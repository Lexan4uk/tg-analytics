# Документация

## Навигация  
- [Запуск проекта](#запуск-проекта)  
- [Архитектура](#архитектура)
- [Принятые решения](#принятые-решения)  
- [Использование AI](#использование-ai)  
- [Свои мысли](#свои-мысли)
  
## Запуск проекта

Для запуска надо запуллить/скачать зип. В корне проекта .env.example, можно скопировать его в просто .env, добавить BOT_TOKEN, GEMINI_API_KEY. Далее забилдить docker-compose up --build, готово.


Учтите, что как вы и просили, Redis кэшрует сообщения на 20 минут, так что для того, что бы смотреть аналитику в "реальном времени" кэш надо чистить docker-compose exec redis redis-cli FLUSHALL, так же можно поменять CACHE_TTL_MIN в .env, тогда кэшироваться будет чаще.


Для работы тестов надо перейти в cd apps/bot и скачать зависимости npm i, далее заработает npm test.

## Архитектура

Реализован монорепозиторием

```bash
/apps
  /bot        — Telegram-бот (Telegraf)
  /web        — Web-интерфейс (Next.js)
/db
  /init       — SQL-инициализация БД
```

Использовался ваш стэк:

Node.js + TypeScript

Telegraf — Telegram Bot API

Next.js (App Router) — Web-интерфейс и API routes

PostgreSQL — основное хранилище данных

Redis — кэширование статистики

Gemini API — LLM-анализ сообщений

Docker Compose — инфраструктура


## Принятые решения

Пройдусь по вашим блокам:

<h3>Сбор данных:</h3>

*Бот сохраняет:*

- чаты (chats)

- пользователей (users)

- текстовые сообщения (messages)

*Особенности:*

- используется чистый SQL без ORM

- каждая таблица инкапсулирована в отдельной модели

- при инициализации бота открывается http://localhost:3001/health для проверки работоспособности контейнера. В бизнес логике не учавствует.


<h3>Статистика:</h3>

*Команда /stats открывает inline-меню со статистикой*:

- топ-10 пользователей по количеству сообщений

- статистика конкретного пользователя

*фильтры по времени (время сохраняется в UTC):*

- сегодня

- неделя

- месяц

- всё время

*Кэширование:*

- результаты статистики кэшируются в Redis

- TTL задаётся через CACHE_TTL_MIN (по умолчанию 20 минут)


<h3>LLM-интеграция:</h3>

*Команды:*

- /analyze @username

- /analyze (в ответ на сообщение пользователя)

*Логика:*

- Получение последних 50–100 сообщений пользователя

- Формирование промпта

- Запрос к Gemini API

- Парсинг JSON-ответа

- Форматированный вывод результата

*Анализ включает:*

- стиль общения

- основные темы

- среднюю длину сообщений

- активность

- тональность

- частые слова


<h3>Веб-интерфейс:</h3>

*Простой интерфейс на Next.js:*

- поле ввода username

- кнопка «Анализировать»

- вывод результата анализа

*Реализация:*

- используется API route /api/analyze

- логика анализа повторяет поведение команды /analyze в боте


<h3>Своё:</h3>

/activity — активность чата по времени суток

*Команда /activity показывает распределение сообщений по времени суток:*

- ночь (00–06)

- утро (06–12)

- день (12–18)

- вечер (18–24)

- Также определяется период максимальной активности.

*Зачем:*

- помогает понять, когда участники чата наиболее активны

- полезно для администраторов и аналитики


<h3>Тесты:</h3>

Используется Vitest, изолированы от инфраструктуры.

*Написаны unit-тесты для:*

- утилит работы с временными диапазонами

- форматирования отображения пользователей

- логики кэширования статистики

- обработки ответов LLM

*Особенности:*

- все внешние зависимости замоканы

- PostgreSQL, Redis и Gemini API не поднимаются

тесты запускаются командой:

```bash
npm test
```

## Использование AI

Во время работы использовал в основном браузерный ChatGPT, отделённый от VS Code. Иногда использовал CODEX для лёгкой замены проблемных моментов в коде.

Сначала я по вашему документу сделал с ChatGPT базу - минимальный бот отвечающий одним сообщением и пустое Next приложение, запускающееся с докера. Далее последовательно наполнял по вашим пунктам.

Дорабатывать приходилось моменты докера т.к. я сам с ним не очень опытный, так же сильно страдал с адекватной подгрузкой .env переменных, из неприятных UX ошибок - клик по одной и той же кнопке более одного раза выдавал ошибку, решил. Так же у гпт не было актуальной документации по 
Gemini, так что код для клиента брал с офф. сайта, ещё была проблема с инициализацией бота - если запускать веб сервис после телеграма, код до него не доходил и веб сервис не запускался, телеграм стопорил выполнение на себе.

Было ещё много мелких ошибок, но я их решал быстро и уже не помню.

Времени сэкономил несчётное количество, потому что мой опыт в докере - 1 видео и 1 маленький проект, так же апи на чистом Node я никогда не делал, запросы сделаны на чистом SQL - я с ним давно не работал, а апи делал только на c# и Prisma, где не нужно напрямую вызывать SQL, с ЛЛМ работал но только локальной ollama, редис использовал в другом проекте лишь раз через сервис Upstash для хренения сессий, с телеграм-ботом игрался на python года 3 назад.

99% кода сгенерировано, если бы я писал сам только на понимание что и как делать ушло бы больше дня.

Справился за 5-6 часов.

## Свои мысли

Сначала думал в чём-нибудь разобраться, но понял, что если не гпт, то за день не управлюсь никак. Я в целом +- разбираюсь именно в веб фронтэнд разработке, и бэком до недавнего времени занимался только на необходимый минимум, но за последнее время попрактиковался. 

Это мой второй проект для которого я организовал докер, первый был NextJS+NestJS+SQlite веб приложение которое я сделал для себя ради использования как шаблоны для дальнейших проектов, и сразу после него в тот же день начал работать над вашим. Большинство времени я просидел в ожидании забилживания докера, так как не подумал заранее что надо было его по-другому организовать, поудобнее для разработки.

Код 100% получился грязнющий, но мне разбираться с ним уже не хочется, поздно. Организация файлов/функций была отдана нейронке.

Тесты в жизни писал только в колледже, принципы и важность понимаю, но в своих работах не использовал. 

В целом, по задаче работает на 100%, нагенерировал успешно.



